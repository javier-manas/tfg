{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d5bce01-b96e-47a5-81fc-bcac5567895f",
   "metadata": {
    "tags": []
   },
   "source": [
    "0. Resumen:\n",
    "Creo que el problema de este codigo esta en el apartado \"2 preprocess data\" en la celda \"Prepare the text inputs for the model\". Creo que e falta alguna instruccion o grupo de instrucciones que preparen los datos de entrada para que el trainer los acepte. \n",
    "\n",
    "Para correr este codigo yo estaba usando google colaboratory, he probado a correrlo aqui y de primeras no me ha funcionado, posiblemente haya que instalar algunas librerias. Es la primera vez que uso este ide y hay mucho que no se.\n",
    "\n",
    "Para este dataset en concreto el codigo no funciona, pero con otro en el cual las labels sean int, en vez de list, si funciona. Un dataset que funcionaria y que he probado seria \"SetFit/emotion\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad37cc0-1434-4c47-8120-ee8f02bc833d",
   "metadata": {},
   "source": [
    "1. Activate GPU and Install Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f765ca4-389b-48d3-89bb-a3a59e771132",
   "metadata": {},
   "source": [
    "# Install required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ac783a1-b908-4b1c-a3dd-8f31b7179ae2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'huggingface_hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Log in to your Hugging Face account \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Get your API token here https://huggingface.co/settings/token\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m notebook_login\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 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\u001b[39;00m\n\u001b[1;32m      8\u001b[0m notebook_login()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'huggingface_hub'"
     ]
    }
   ],
   "source": [
    "# Log in to your Hugging Face account \n",
    "# Get your API token here https://huggingface.co/settings/token\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "\n",
    "# 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\n",
    "\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a2ceb26-0164-4553-a721-ede13c2da9fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Activate GPU for faster training by clicking on 'Runtime' > 'Change runtime type' and then selecting GPU as the Hardware accelerator\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Then check if GPU is available\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "#----\n",
    "# Activate GPU for faster training by clicking on 'Runtime' > 'Change runtime type' and then selecting GPU as the Hardware accelerator\n",
    "# Then check if GPU is available\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf26c07-67b2-4d6a-b58f-06dc49963dd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "2. Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6f9d46-c0ef-4fa0-b3e0-6a653051755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "from datasets import load_dataset\n",
    "imdb = load_dataset(\"mrm8488/go_emotions-es-mt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aafff12-3904-4fd7-ade0-33c0af0c8905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a smaller training dataset for faster training times\n",
    "small_train_dataset = imdb[\"train\"].shuffle(seed=42).select([i for i in list(range(3000))])\n",
    "small_test_dataset = imdb[\"test\"].shuffle(seed=42).select([i for i in list(range(300))])\n",
    "print(small_train_dataset[0])\n",
    "print(small_test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1fbf5c-161e-4db1-93c1-c2eb6fd3ea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set DistilBERT tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606d1591-3864-41ab-af21-e3a94bbf0ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare the text inputs for the model\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text_es\"], truncation=True)\n",
    "\n",
    "# small_train_dataset\n",
    "# small_test_dataset\n",
    "\n",
    "tokenized_train = small_train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_test = small_test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a64af4c-6d0b-4eff-862f-123023ffa5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use data_collector to convert our samples to PyTorch tensors and concatenate them with the correct amount of padding\n",
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edee324-7a59-46a6-b539-9ba6f91690c5",
   "metadata": {},
   "source": [
    "3. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5955fe6-fb6b-471e-b9af-d9e35ba2a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define DistilBERT as our base model:\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3ed6e8-5b04-4ab1-b147-f6fada862395",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the evaluation metrics \n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    load_accuracy = load_metric(\"accuracy\")\n",
    "    load_f1 = load_metric(\"f1\")\n",
    "\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    f1 = load_f1.compute(predictions=predictions, references=labels, average='macro')[\"f1\"]\n",
    "    \n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff94278f-8d29-4683-9c79-2087cce1819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a new Trainer with all the objects we constructed so far\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "repo_name = \"26_04\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=repo_name,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\", \n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b4c493-0fb1-4b08-9b24-8aec2537c8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(imdb['test'][2])\n",
    "print()\n",
    "\n",
    "print(imdb['train'][2])\n",
    "print()\n",
    "imdb['train'].features\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9deae5-169d-41b7-8b3f-83bc227ffc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e991ff2f-6f1f-49b5-80ad-1757b5322293",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute the evaluation metrics\n",
    "trainer.evaluate()\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de159d54-65a2-4fef-8a97-114e526f1ce9",
   "metadata": {},
   "source": [
    "4. Analyzing new data with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41b1b84-dc00-44b4-a576-052fd15892b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the model to the Hub\n",
    "trainer.push_to_hub()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73be919a-e417-4008-afa0-8fc06f176876",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Run inferences with your new model using Pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "sentiment_model = pipeline(model=\"mrovejaxd/26-04\")\n",
    "\n",
    "sentiment_model([\"I like you. I love you\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JM Env (Python 3.9)",
   "language": "python",
   "name": "jm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
